diff --git a/Experiments/Ablation-Experiment/ablation_experiment.sh b/Experiments/Ablation-Experiment/ablation_experiment.sh
index c8c69b1..38c93ef 100755
--- a/Experiments/Ablation-Experiment/ablation_experiment.sh
+++ b/Experiments/Ablation-Experiment/ablation_experiment.sh
@@ -2,17 +2,19 @@
 
 set -e
 
-ModelarDB_vanilla_path="../../ModelarDB-versions/ModelarDB-GorillaV/"
+ModelarDB_vanilla_path="../../ModelarDB-versions/ModelarDB/"
 # Where ModelarDB stores data
 ModelarDB_Data="../../ModelarDB-versions/data/"
 
 # TODO: confirm that path to ModelarDB Utilities is correct
-ingestion_script="~/Utilities/Apache-Parquet-Loader/main.py"
+ingestion_script="../../Utilities/ingest_parquet_to_modelardb.py"
 output_dir=$(pwd)
 
 table_name=$1
 data_dir=$2
-error_bounds="0 0.01 0.1 1 5 10"
+
+#error_bounds="0 0.01 0.1 1 5 10"
+error_bounds="0 0.01 0.1"
 # ModelarDB's default port number
 port="127.0.0.1:9999"
 # time to sleep for vacuum
@@ -52,32 +54,31 @@ stop_modelardb() {
 }
 
 compress_error_bounds() {
-    for patch in $pmc_only_patch $pmc_and_swing_only_patch $swing_only_patch $gorilla_only_patch; do
-        cd $ModelarDB_vanilla_path
-        git restore .
-        git apply $patch
+    for patch in $gorilla_only_patch; do
+        #git restore .
+        #git apply $patch
         patch_name=$(basename -s .patch "$patch")
         echo "Patch name is: $patch_name"
         for error_bound in $error_bounds; do
             # Ensure release build is done
-            # cargo build --release --manifest-path $1/Cargo.toml
-            # start_modelardb $1/target/release/modelardbd
+            cargo build --release --manifest-path $1/Cargo.toml
+            start_modelardb $1/target/release/modelardbd
             results_file=$patch_name-$error_bound-$table_name-compression_results.log
             # timing ingestion process
             start=$SECONDS
-            # python3 $ingestion_script "127.0.0.1:9999" $table_name $data_dir $error_bound
+            python3 $ingestion_script "127.0.0.1:9999" $table_name $data_dir $error_bound
             # sleep for a minute or two to finish vacuuming
             duration=$((SECONDS-start))
             # write results of the python program logs to the common file
-            # sleep $sleep_for_vacuum
+            sleep $sleep_for_vacuum
             echo "Compressed in $duration seconds" > $results_file
             compression_size=$(du -h -d0 $ModelarDB_Data)
             echo "Compression size: $compression_size" >> $results_file
             # stop ModelarDB
-            # stop_modelardb
-            # sleep $sleep_for_vacuum
+            stop_modelardb
+            sleep $sleep_for_vacuum
             # We remove old data after each ingestion
-            # clean_modelar_data
+            clean_modelar_data
         done
     done
 }
@@ -87,8 +88,9 @@ compress_error_bounds() {
 # Main function
 clean_modelar_data
 # start new round with modified modelardb
+cd $ModelarDB_vanilla_path
 for path in $ModelarDB_vanilla_path; do
     echo "Starting: $path"
     # compress_error_bounds $path
     compress_error_bounds $path
-done
\ No newline at end of file
+done
diff --git a/Experiments/Ablation-Experiment/gorilla_only.patch b/Experiments/Ablation-Experiment/gorilla_only.patch
index 7c17fc6..e69de29 100644
--- a/Experiments/Ablation-Experiment/gorilla_only.patch
+++ b/Experiments/Ablation-Experiment/gorilla_only.patch
@@ -1,27 +0,0 @@
-diff --git a/ModelarDB-versions/ModelarDB-GorillaV/crates/modelardb_compression/src/compression.rs b/ModelarDB-versions/ModelarDB-GorillaV/crates/modelardb_compression/src/compression.rs
-index 62c7906..c1ebcab 100644
---- a/ModelarDB-versions/ModelarDB-GorillaV/crates/modelardb_compression/src/compression.rs
-+++ b/ModelarDB-versions/ModelarDB-GorillaV/crates/modelardb_compression/src/compression.rs
-@@ -80,7 +80,8 @@ pub fn try_compress(
- 
-         // The model will only be stored as part of a compressed segment if it uses less storage
-         // space per value than the uncompressed values it represents.
--        if model.bytes_per_value <= models::VALUE_SIZE_IN_BYTES as f32 {
-+        if false {
-+        // if model.bytes_per_value <= models::VALUE_SIZE_IN_BYTES as f32 {
-             // Flush the previous model and any residual value if either exists.
-             if current_start_index > 0 {
-                 store_compressed_segments_with_model_and_or_residuals(
-diff --git a/ModelarDB-versions/ModelarDB-GorillaV/crates/modelardb_compression/src/types.rs b/ModelarDB-versions/ModelarDB-GorillaV/crates/modelardb_compression/src/types.rs
-index 46a26c3..e19b759 100644
---- a/ModelarDB-versions/ModelarDB-GorillaV/crates/modelardb_compression/src/types.rs
-+++ b/ModelarDB-versions/ModelarDB-GorillaV/crates/modelardb_compression/src/types.rs
-@@ -74,7 +74,7 @@ impl ModelBuilder {
- 
-         self.swing_could_fit_all =
-             self.swing_could_fit_all && self.swing.fit_data_point(timestamp, value);
--
-+        
-         self.pmc_mean_could_fit_all || self.swing_could_fit_all
-     }
- 
diff --git a/ModelarDB-versions/ModelarDB/crates/modelardb_compression/src/compression.rs b/ModelarDB-versions/ModelarDB/crates/modelardb_compression/src/compression.rs
index 62c7906..8c9a473 100644
--- a/ModelarDB-versions/ModelarDB/crates/modelardb_compression/src/compression.rs
+++ b/ModelarDB-versions/ModelarDB/crates/modelardb_compression/src/compression.rs
@@ -80,7 +80,7 @@ pub fn try_compress(
 
         // The model will only be stored as part of a compressed segment if it uses less storage
         // space per value than the uncompressed values it represents.
-        if model.bytes_per_value <= models::VALUE_SIZE_IN_BYTES as f32 {
+        if false {
             // Flush the previous model and any residual value if either exists.
             if current_start_index > 0 {
                 store_compressed_segments_with_model_and_or_residuals(
diff --git a/data/README.txt b/data/README.txt
deleted file mode 100644
index d6154dc..0000000
--- a/data/README.txt
+++ /dev/null
@@ -1,2 +0,0 @@
-This dataset is open dataset published as part of the paper "Evaluating the impact of error-bounded lossy compression on time series forecasting" in EDBT 2024 by C. E. Mu√±iz-Cuza, S. K. Jensen, B. Jonas, H. Nguyen, and P. Torben Bach.
-Link to original dataset: https://github.com/cmcuza/EvalImpLSTS/tree/main/data/raw/Wind 
diff --git a/data/wind.parquet b/data/wind.parquet
deleted file mode 100644
index 8ee45f2..0000000
Binary files a/data/wind.parquet and /dev/null differ
